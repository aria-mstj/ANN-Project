{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fruit-360 project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEG3SPkhNSZZ"
      },
      "source": [
        "# 1- Reading from dataset\n",
        "First of all, we'll need a dataset to train our model but before adding that, we should add numpy library to our project. \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRARdVdZ9fW"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdsoUzG8NRO7"
      },
      "source": [
        "In this project, I used Fruit-360 dataset which you can find [here](https://www.kaggle.com/moltean/fruits). To facilitate the work, only 4 types of fruit have been used in this project.\\\\ \n",
        "In our dataset, each class has about 491 pictures in 100 * 100 dimensions.Therefore, if we want to directly add image pixels to our neural network, our input layer will have 10000 neurons, which makes the network very heavy.For solving this problem 360 features have been extracted using feature extraction techniques.Then, using feature vector size reduction techniques, this size is reduced to 102, which we consider as the input of the neural network. Knowing that our model should eventually recognize one of four models of fruit, our output layer has 4 neurons that represents the predicted fruit. Our model also has two hidden layers, first with 150 neurons and second with 60 neurons.I used sigmoid function as activation function of all layers.\n",
        "Our model structure looks like this :\n",
        "![picture](https://drive.google.com/uc?export=view&id=1dws_Rl93GR5eHVx9f3Ma5nfT_dWzS2mg)\n",
        "\n",
        "Our main idea is to work with train data and to evaluate it with test data.In each of our iterations we divide our data into mini batches, calculate the gradient of each batch, calculate its average and add then, apply changes. This approach results in lower computational complexity in each iteration and reduce total computation time.\\\\ \n",
        "For reading dataset, four datasets have been prepared, train_set_features.pkl, test_set_features.pkl, train_set_labels.pkl an test_set_labels.pkl. For reading datasets and reducing dimensions,\n",
        "we construct two functions named ```get_testset``` and ```get_trainset```.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh7ETmDnUXlS"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "def get_trainset():\n",
        "    f = open(\"train_set_features.pkl\", \"rb\")\n",
        "    train_set_features2 = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    # reducing feature vector length\n",
        "    features_STDs = np.std(a=train_set_features2, axis=0)\n",
        "    train_set_features = train_set_features2[:, features_STDs > 52.3]\n",
        "\n",
        "    # changing the range of data between 0 and 1\n",
        "    train_set_features = np.divide(train_set_features, train_set_features.max())\n",
        "\n",
        "    # loading training set labels\n",
        "    f = open(\"train_set_labels.pkl\", \"rb\")\n",
        "    train_set_labels = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "    train_set = []\n",
        "\n",
        "    for i in range(len(train_set_features)):\n",
        "        label = np.array([0, 0, 0, 0])\n",
        "        label[int(train_set_labels[i])] = 1\n",
        "        label = label.reshape(4, 1)\n",
        "        train_set.append((train_set_features[i].reshape(102, 1), label))\n",
        "\n",
        "    random.shuffle(train_set)\n",
        "\n",
        "    return train_set\n",
        "\n",
        "def get_testset():\n",
        "\n",
        "    # loading test set features\n",
        "    f = open(\"test_set_features.pkl\", \"rb\")\n",
        "    test_set_features2 = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    # reducing feature vector length\n",
        "    features_STDs = np.std(a=test_set_features2, axis=0)\n",
        "    test_set_features = test_set_features2[:, features_STDs > 48]\n",
        "\n",
        "    # changing the range of data between 0 and 1\n",
        "    test_set_features = np.divide(test_set_features, test_set_features.max())\n",
        "\n",
        "    # loading test set labels\n",
        "    f = open(\"test_set_labels.pkl\", \"rb\")\n",
        "    test_set_labels = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    # ------------\n",
        "    test_set = []\n",
        "\n",
        "    for i in range(len(test_set_features)):\n",
        "        label = np.array([0, 0, 0, 0])\n",
        "        label[int(test_set_labels[i])] = 1\n",
        "        label = label.reshape(4, 1)\n",
        "        test_set.append((test_set_features[i].reshape(102, 1), label))\n",
        "\n",
        "    # shuffle\n",
        "    random.shuffle(test_set)\n",
        "\n",
        "    # print(len(test_set)) #662\n",
        "    return test_set\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xnuf_7zceCt"
      },
      "source": [
        "Adding local files to google colab.\n",
        "You can find these files on git repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "EhbJFIiAbFRq",
        "outputId": "9a8ac1a1-c5ed-4f56-bf48-af1b36cacef7"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f789ca4-7e60-4c93-922b-bcb09d1f821f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f789ca4-7e60-4c93-922b-bcb09d1f821f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_set_features.pkl to test_set_features (1).pkl\n",
            "Saving test_set_labels.pkl to test_set_labels (1).pkl\n",
            "Saving train_set_features.pkl to train_set_features (1).pkl\n",
            "Saving train_set_labels.pkl to train_set_labels (1).pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIrXokYcm5y"
      },
      "source": [
        "Calling our train function to make sure it works fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uYmCpBfcmml",
        "outputId": "e38aedd8-6607-4405-e6da-06e9a85922d2"
      },
      "source": [
        "train_set = np.array(get_trainset())\n",
        "train_set.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1962, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7NftatIdbbu"
      },
      "source": [
        "First five features of first picture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKdEAxEua_EY",
        "outputId": "fc3673ee-e04b-4914-dff6-2342e3fbf8e6"
      },
      "source": [
        "train_set[0][0][:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63082213],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJQxCvXSdoHf"
      },
      "source": [
        "# 2- Feed forward\n",
        "In order to calculate the output of a neural network, each layers output is calculated based on following formula : \\\\\n",
        "\n",
        "<center> $a ^ {(L+1)} = \\sigma (W^{L+1} \\times a^L + b^{L+1})$ \n",
        "\n",
        "<p align = left> Therefore, for weight and biases between layers we assign matrix. Weigth matrixes are shown with W_k, where k is the number of layer, and biases with b_k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03N8kAydQwY"
      },
      "source": [
        "feature_count = len(train_set[0][0])\n",
        "\n",
        "first_layer_neurons = 150\n",
        "second_layer_neurons = 60\n",
        "output_neurons = len(train_set[0][1])\n",
        "\n",
        "W_1 = np.random.randn(first_layer_neurons * feature_count).reshape(first_layer_neurons, feature_count)\n",
        "b_1 = np.zeros((first_layer_neurons, 1))\n",
        "\n",
        "W_2 = np.random.randn(second_layer_neurons * first_layer_neurons).reshape(second_layer_neurons, first_layer_neurons)\n",
        "b_2 = np.zeros((second_layer_neurons, 1))\n",
        "\n",
        "W_3 = np.random.randn(output_neurons * second_layer_neurons).reshape(output_neurons, second_layer_neurons)\n",
        "b_3 = np.zeros((output_neurons, 1))\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUfn3KZKhlTn"
      },
      "source": [
        "def sigmoid(x):\n",
        "   return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJOrx8rhgGm"
      },
      "source": [
        "After initializing weights and biases and defining sigmoid function, we seperate first 200 images of our train dataset, and then calculate the output based in the formula.\n",
        "\n",
        "For calculating the accuracy of our model, we compare the calculated output with label. We expect a mean of 25% accuracy because we assigned weight randomly and we have 4 different labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyGKJxWNpPIR",
        "outputId": "8d8e61cc-97e4-4450-a5a1-0314670bb653"
      },
      "source": [
        "X = [i[0] for i in train_set[:200]]\n",
        "Y = [i[1] for i in train_set[:200]]\n",
        "# print(len(Y[0]))\n",
        "corrects = 0\n",
        "for i, x in enumerate(X):\n",
        "    # x = np.array(x)\n",
        "    # print(x.shape)\n",
        "    # print(W_1.shape)\n",
        "    A1 = sigmoid(W_1 @ x + b_1)\n",
        "    A2 = sigmoid(W_2 @ A1 + b_2)\n",
        "    out = sigmoid(W_3 @ A2 + b_3)\n",
        "    answer = list(out).index(max(out))\n",
        "    # print(answer)\n",
        "    # print(out)\n",
        "    if answer == list(Y[i]).index(1):\n",
        "        corrects += 1\n",
        "    # print(out)\n",
        "\n",
        "accuracy = (corrects / 200) * 100\n",
        "print(accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNmtbjAvp8Qe"
      },
      "source": [
        "# 3- Backpropagation\n",
        "One of our main goals during the learning process is to minimize the cost function.\n",
        "\n",
        "<center> $Cost = \\sum_{j=0}^{n_L-1}(a_j^L - y_j) ^ 2$\n",
        "\n",
        "<p align = left> In order to minimize the cost function, we use gradient descent, that means taking partial derivative of cost function for all variables.\n",
        "\n",
        "<center> $ (W, b) = (W, b) - \\alpha \\triangle Cost$\n",
        "<p align = left> We take derivatives with help of backpropagation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnba_pMdpiRR"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMlzDuCssb3D"
      },
      "source": [
        "def sig_pr(x):\n",
        "    return np.exp(-x) / ((1 + np.exp(-x)) ** 2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuoDqa0tsdIg"
      },
      "source": [
        "train_set = get_trainset()\n",
        "test_set = get_testset()\n",
        "Xt = [i[0] for i in test_set]\n",
        "Yt = [i[1] for i in test_set]\n",
        "\n",
        "pics_count = 491\n",
        "train_set = train_set[:200]\n",
        "X = [i[0] for i in train_set]\n",
        "Y = [i[1] for i in train_set]\n",
        "feature_count = len(X[0])\n",
        "\n",
        "W_1 = np.random.randn(150 * feature_count).reshape(150, feature_count)\n",
        "b_1 = np.zeros((150, 1))\n",
        "\n",
        "W_2 = np.random.randn(60 * 150).reshape(60, 150)\n",
        "b_2 = np.zeros((60, 1))\n",
        "\n",
        "W_3 = np.random.randn(4 * 60).reshape(4, 60)\n",
        "b_3 = np.zeros((4, 1))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHKZnIPEsij0"
      },
      "source": [
        "corrects = 0\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "learning_rate = 1\n",
        "total_costs = []"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSZ22lzPs2mY"
      },
      "source": [
        "Knowing we have four layers(one input layer, one output layer, two hidden layers), we should calculate derivatives as shown below:\n",
        "\n",
        "We define cost, $a_j$ and $z_j$ as follows.\n",
        "\n",
        "<center> $Cost = \\sum_{j=0}^{3}(a_j^L - y_j) ^ 2$\n",
        "\n",
        "$z_j^{(3)} = \\sum_{j=0}^{3} w_{jk}^{(3)} a_k ^{2} + b_j^{(2)}$\n",
        "\n",
        "$a_j^{(3)} = \\sigma(z_j^{(3)})$\n",
        "\n",
        "\n",
        "<p align = \"left\"> For weight and bias we apply derivative chain rule. \n",
        "</p>\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial w_{jk}^{(3)}} = \\frac{\\partial Cost}{\\partial a_j^{(3)}} \\times \\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}} \\times \\frac{\\partial z_j^{(3)}}{\\partial w_{jk}^{(3)}} = 2(a_j^{(3)} - y_j) \\times \\sigma^{'}(z_j^{(3)}) \\times a_k^{(2)}$\n",
        "\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b_{j}^{(3)}} = \\frac{\\partial Cost}{\\partial a_j^{(3)}} \\times \\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}} \\times \\frac{\\partial z_j^{(3)}}{\\partial b_{j}^{(3)}} = 2(a_j^{(3)} - y_j) \\times \\sigma^{'}(z_j^{(3)}) \\times 1$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial a_{k}^{(2)}} = \\sum_{j=0}^{59}\\frac{\\partial Cost}{\\partial a_j^{(3)}} \\times \\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}} \\times \\frac{\\partial z_j^{(3)}}{\\partial a_{k}^{(2)}} = \\sum_{j=0}^{59}(2(a_j^{(3)} - y_j) \\times \\sigma^{'}(z_j^{(3)}) \\times w_{jk}^{(3)})$\n",
        "\n",
        "\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial w_{km}^{(2)}} = \\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\frac{\\partial a_k^{(2)}}{\\partial z_k^{(2)}} \\times \\frac{\\partial z_k^{(2)}}{\\partial w_{km}^{(2)}} = \\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\sigma^{'}(z_k^{(2)}) \\times a_m^{(1)}$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b_{k}^{(2)}} = \\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\frac{\\partial a_k^{(2)}}{\\partial z_k^{(2)}} \\times \\frac{\\partial z_k^{(2)}}{\\partial b_{k}^{(2)}} = \\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\sigma^{'}(z_k^{(2)}) \\times 1$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial a_{m}^{(1)}} = \\sum_{j=0}^{149}\\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\frac{\\partial a_k^{(2)}}{\\partial z_k^{(2)}} \\times \\frac{\\partial z_k^{(2)}}{\\partial a_{m}^{(1)}} = \\sum_{j=0}^{149} (\\frac{\\partial Cost}{\\partial a_k^{(2)}} \\times \\sigma^{'}(z_k^{(2)}) \\times w_{km}^{(2)})$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial w_{mv}^{(1)}} = \\frac{\\partial Cost}{\\partial a_m^{(1)}} \\times \\frac{\\partial a_m^{(1)}}{\\partial z_m^{(1)}} \\times \\frac{\\partial z_m^{(1)}}{\\partial w_{mv}^{(1)}} = \\frac{\\partial Cost}{\\partial a_m^{(1)}} \\times \\sigma^{'}(z_m^{(1)}) \\times a_v^{(0)}$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b_{m}^{(1)}} = \\frac{\\partial Cost}{\\partial a_m^{(1)}} \\times \\frac{\\partial a_m^{(1)}}{\\partial z_m^{(1)}} \\times \\frac{\\partial z_m^{(1)}}{\\partial b_{m}^{(1)}} = \\frac{\\partial Cost}{\\partial a_m^{(1)}} \\times \\sigma^{'}(z_m^{(1)}) \\times 1$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-apudBmWsqE8",
        "outputId": "3e8c1247-3162-48d1-b327-c1a6aa0cd7c8"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    batches = []\n",
        "    print(\"EPOCHS : \", epoch)\n",
        "    for x in range(0, len(X), batch_size):\n",
        "        batches.append(train_set[x:x+batch_size])\n",
        "    for i, batch in enumerate(batches):\n",
        "        # print(f\"number of batch {i}\")\n",
        "        grad_w1 = np.zeros((150, feature_count))\n",
        "        grad_w2 = np.zeros((60, 150))\n",
        "        grad_w3 = np.zeros((4, 60))\n",
        "\n",
        "        grad_b1 = np.zeros((150, 1))\n",
        "        grad_b2 = np.zeros((60, 1))\n",
        "        grad_b3 = np.zeros((4, 1))\n",
        "\n",
        "        for x, y in batch:\n",
        "            A1 = sigmoid(W_1 @ x + b_1)\n",
        "            A2 = sigmoid(W_2 @ A1 + b_2)\n",
        "            out = sigmoid(W_3 @ A2 + b_3)\n",
        "\n",
        "            for j in range(grad_w3.shape[0]):\n",
        "                for k in range(grad_w3.shape[1]):\n",
        "                    grad_w3[j, k] += 2 * (out[j, 0] - y[j, 0]) * out[j, 0] * (1 - out[j, 0]) * A2[k, 0]\n",
        "\n",
        "            for j in range(grad_w3.shape[0]):\n",
        "                grad_b3[j, 0] += 2 * (out[j, 0] - y[j, 0]) * out[j, 0] * (1 - out[j, 0])\n",
        "\n",
        "            delta_3 = np.zeros((grad_w3.shape[1], 1))\n",
        "            for k in range(grad_w3.shape[1]):\n",
        "                for j in range(grad_w3.shape[0]):\n",
        "                    delta_3[k, 0] += 2 * (out[j, 0] - y[j, 0]) * out[j, 0] * (1 - out[j, 0]) * W_3[j, k]\n",
        "\n",
        "            for k in range(grad_w2.shape[0]):\n",
        "                for m in range(grad_w2.shape[1]):\n",
        "                    # print(type(delta_3))\n",
        "                    grad_w2[k, m] += delta_3[k, 0] * A2[k, 0] * (1 - A2[k, 0]) * A1[m, 0]\n",
        "\n",
        "            for k in range(grad_w2.shape[0]):\n",
        "                grad_b2[k, 0] += delta_3[k, 0] * A2[k, 0] * (1- A2[k, 0])\n",
        "\n",
        "            delta_2 = np.zeros((grad_w2.shape[1], 1))\n",
        "            for m in range(grad_w2.shape[1]):\n",
        "                for k in range(grad_w2.shape[0]):\n",
        "                    delta_2[m, 0] += delta_3[k, 0] * A2[k, 0] * (1 - A2[k, 0]) * W_2[k, m]\n",
        "\n",
        "            for m in range(grad_w1.shape[0]):\n",
        "                for v in range(grad_w1.shape[1]):\n",
        "                    grad_w1[m, v] += delta_2[m, 0] * A1[m, 0] * (1 - A1[m, 0]) * x[v, 0]\n",
        "\n",
        "            for m in range(grad_w1.shape[0]):\n",
        "                grad_b1[m, 0] += delta_2[m, 0] * A1[m, 0] * (1 - A1[m, 0])\n",
        "\n",
        "        # print(grad_w3)\n",
        "        W_3 = W_3 - (learning_rate * (grad_w3 / batch_size))\n",
        "        W_2 = W_2 - (learning_rate * (grad_w2 / batch_size))\n",
        "        W_1 = W_1 - (learning_rate * (grad_w1 / batch_size))\n",
        "\n",
        "        b_3 = b_3 - (learning_rate * (grad_b3 / batch_size))\n",
        "        b_2 = b_2 - (learning_rate * (grad_b2 / batch_size))\n",
        "        b_1 = b_1 - (learning_rate * (grad_b1 / batch_size))\n",
        "\n",
        "    cost = 0\n",
        "    for train_data in train_set:\n",
        "        a0 = train_data[0]\n",
        "        a1 = sigmoid(W_1 @ a0 + b_1)\n",
        "        a2 = sigmoid(W_2 @ a1 + b_2)\n",
        "        a3 = sigmoid(W_3 @ a2 + b_3)\n",
        "\n",
        "        for j in range(4):\n",
        "            cost += np.power((a3[j, 0] - train_data[1][j, 0]), 2)\n",
        "\n",
        "    print(cost)\n",
        "    cost /= 100\n",
        "    total_costs.append(cost)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCHS :  0\n",
            "228.072669577029\n",
            "EPOCHS :  1\n",
            "186.08422480982878\n",
            "EPOCHS :  2\n",
            "58.305654864043596\n",
            "EPOCHS :  3\n",
            "18.902652986284277\n",
            "EPOCHS :  4\n",
            "14.03246537479083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GjKV_mo9fhZu",
        "outputId": "9f8caace-7dee-4623-e1bd-fb10ba5c742f"
      },
      "source": [
        "epoch_size = [x for x in range(epochs)]\n",
        "plt.plot(epoch_size, total_costs)\n",
        "plt.savefig('5_epoch_backpropagation.png')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWJA6uZJhH8r",
        "outputId": "6d433b61-9da6-4d34-d13e-d7713771027b"
      },
      "source": [
        "corrects = 0\n",
        "\n",
        "for i, test_data in enumerate(Xt):\n",
        "    a0 = test_data\n",
        "    a1 = sigmoid(W_1 @ a0 + b_1)\n",
        "    a2 = sigmoid(W_2 @ a1 + b_2)\n",
        "    a3 = sigmoid(W_3 @ a2 + b_3)\n",
        "    # print(f\"TEST : {Yt[i]}, PREDICT : {a3}\")\n",
        "\n",
        "    predicted_number = list(a3).index(max(a3))\n",
        "    real_number = list(Yt[i]).index(1)\n",
        "\n",
        "    if predicted_number == real_number:\n",
        "        corrects += 1\n",
        "accuracy = corrects / len(Xt)\n",
        "print(\"Accuracy = \", accuracy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.9969788519637462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBb20okzjMQt"
      },
      "source": [
        "# 4- Vectorization\n",
        "For the reason of long execution time, until now we have worked with first 200 pics and runed our code for only 5 epochs. For solving this problem we can use vectorization instead of for loops.\n",
        "\n",
        "As a result, the processing time would be reduced significantly.The explanation for this is that matrix operations can run in parallel on multi-core CPUs. Furthermore, today's processors have instructions for working with large vector data, which will be much more effective.\n",
        "\n",
        "\n",
        "---\n",
        "In vectorized notation, we define cost, $a_j$ and $z_j$ as follows.\n",
        "\n",
        "<center> $Cost = (\\overrightarrow{a^{(3)}} - \\overrightarrow{y}) ^ T$\n",
        "\n",
        "<center> $\\overrightarrow{a}^{(3)} = \\sigma(\\overrightarrow{z}^{(3)})$\n",
        "\n",
        "<center> $\\overrightarrow{z}^{(3)} = W^{(3)}\\overrightarrow{a}^{(2)} + \\overrightarrow{b}^{(2)}$\n",
        "\n",
        "<p align = \"left\"> For weight and bias we apply derivative chain rule. \n",
        "</p>\n",
        "\n",
        "<center> ${a^{(3)}}^{(')} = a^{(3)}(1 - a^{(3)}) $\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial W^{(3)}} = 2(\\overrightarrow{a}^{(3)} - \\overrightarrow{y}) \\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)}) \\cdot \\overrightarrow{a}^{(2)}  $ \n",
        "\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b^{(3)}} = 2(\\overrightarrow{a}^{(3)} - \\overrightarrow{y}) \\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)}) $\n",
        "\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial a^{(2)}} = {W^{(3)}}^T (2(\\overrightarrow{a}^{(3)} - \\overrightarrow{y}) \\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)}))  $ \n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial W^{(2)}} = \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}} \\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)}) \\cdot \\overrightarrow{a}^{(1)}  $ \n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b^{(2)}} = \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}} \\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)})  $\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial a^{(1)}} = {W^{(2)}}^T \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}} \\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)})$\n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial W^{(1)}} = \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(1)}} \\overrightarrow{a}^{(1)}(1 - \\overrightarrow{a}^{(1)}) \\cdot \\overrightarrow{a}^{(0)}  $ \n",
        "\n",
        "<center> $\\frac{\\partial Cost}{\\partial b^{(1)}} = \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(1)}} \\overrightarrow{a}^{(1)}(1 - \\overrightarrow{a}^{(1)})  $ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar6oBPMbhMju"
      },
      "source": [
        "def sigmoid(x):\n",
        "   return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sig_pr(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejlgZ2nlqsup"
      },
      "source": [
        "def backpropagation(W_1, W_2, W_3, b_1, b_2, b_3, A1, A2, out, Y, X):\n",
        "    dout = 2 * (out - Y)\n",
        "    \n",
        "    dout_dw3 = sig_pr(W_3 @ A2 + b_3) @ A2.transpose()\n",
        "    d_w3 = np.array(dout * dout_dw3)\n",
        "    d_b3 = dout * sig_pr(W_3 @ A2 + b_3)\n",
        "\n",
        "    dout_da2 = W_3.transpose() @ sig_pr(W_3 @ A2 + b_3)\n",
        "    da2_dw2 = sig_pr(W_2 @ A1 + b_2) @ A1.transpose()\n",
        "    da2 = W_3.transpose() @ (dout * sig_pr(W_3 @ A2 + b_3))\n",
        "\n",
        "\n",
        "    d_w2 = da2 * da2_dw2\n",
        "    d_b2 = da2 * sig_pr(W_2 @ A1 + b_2)\n",
        "\n",
        "    da2_da1 = W_2.transpose() @ sig_pr(W_2 @ A1 + b_2)\n",
        "    da1_dw1 = sig_pr(W_1 @ X + b_1) @ X.transpose()\n",
        "\n",
        "    da1 = W_2.transpose() @ (da2 * sig_pr(W_2 @ A1 + b_2))\n",
        "    d_w1 = da1 * da1_dw1\n",
        "    d_b1 = da1 * sig_pr(W_1 @ X + b_1)\n",
        "\n",
        "    return d_w1, d_w2, d_w3, d_b1, d_b2, d_b3\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ9Br-3pqx7g"
      },
      "source": [
        "pics_count = 491# 100 * 100\n",
        "\n",
        "test_set = get_testset()\n",
        "train_set = get_trainset()\n",
        "\n",
        "feature_count = len(train_set[0][0])\n",
        "\n",
        "first_layer_neurons = 150\n",
        "second_layer_neurons = 60\n",
        "output_neurons = len(train_set[0][1])\n",
        "\n",
        "W_1 = np.random.randn(first_layer_neurons * feature_count).reshape(first_layer_neurons, feature_count)\n",
        "b_1 = np.zeros((first_layer_neurons, 1))\n",
        "\n",
        "W_2 = np.random.randn(second_layer_neurons * first_layer_neurons).reshape(second_layer_neurons, first_layer_neurons)\n",
        "b_2 = np.zeros((second_layer_neurons, 1))\n",
        "\n",
        "W_3 = np.random.randn(output_neurons * second_layer_neurons).reshape(output_neurons, second_layer_neurons)\n",
        "b_3 = np.zeros((output_neurons, 1))\n",
        "\n",
        "# print(len(test_set[0][0]))\n",
        "X = [i[0] for i in train_set]\n",
        "Y = [i[1] for i in train_set]\n",
        "\n",
        "Xt = [i[0] for i in test_set]\n",
        "Yt = [i[1] for i in test_set]\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4QLpko2rJhW"
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 20\n",
        "learning_rate = 1\n",
        "total_costs = []"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_jsjc47tmH9",
        "outputId": "11339c2d-3d84-41a4-df30-a06605d055e7"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    batches = []\n",
        "    print(\"EPOCHS : \", epoch)\n",
        "\n",
        "\n",
        "    for x in range(0, len(X), batch_size):\n",
        "        batches.append(train_set[x:x+batch_size])\n",
        "    for i, batch in enumerate(batches):\n",
        "        # print(f\"number of batch {i}\")\n",
        "        grad_w1 = np.zeros((150, feature_count))\n",
        "        grad_w2 = np.zeros((60, 150))\n",
        "        grad_w3 = np.zeros((4, 60))\n",
        "\n",
        "        grad_b1 = np.zeros((150, 1))\n",
        "        grad_b2 = np.zeros((60, 1))\n",
        "        grad_b3 = np.zeros((4, 1))\n",
        "\n",
        "\n",
        "        for x, y in batch:\n",
        "            A1 = sigmoid(W_1 @ x + b_1)\n",
        "            A2 = sigmoid(W_2 @ A1 + b_2)\n",
        "            out = sigmoid(W_3 @ A2 + b_3)\n",
        "            # print(W_3.shape)\n",
        "\n",
        "            gw1, gw2, gw3, gb1, gb2, gb3 = backpropagation(W_1, W_2, W_3, b_1, b_2, b_3, A1, A2, out\n",
        "                                                                                       , y, x)\n",
        "            grad_w1 += gw1\n",
        "            grad_w2 += gw2\n",
        "            grad_w3 += gw3\n",
        "\n",
        "            grad_b1 += gb1\n",
        "            grad_b2 += gb2\n",
        "            grad_b3 += gb3\n",
        "\n",
        "        W_3 = W_3 - (learning_rate * (grad_w3 / batch_size))\n",
        "        W_2 = W_2 - (learning_rate * (grad_w2 / batch_size))\n",
        "        W_1 = W_1 - (learning_rate * (grad_w1 / batch_size))\n",
        "\n",
        "        b_3 = b_3 - (learning_rate * (grad_b3 / batch_size))\n",
        "        b_2 = b_2 - (learning_rate * (grad_b2 / batch_size))\n",
        "        b_1 = b_1 - (learning_rate * (grad_b1 / batch_size))\n",
        "\n",
        "    cost = 0\n",
        "    for train_data in train_set:\n",
        "        a0 = train_data[0]\n",
        "        a1 = sigmoid(W_1 @ a0 + b_1)\n",
        "        a2 = sigmoid(W_2 @ a1 + b_2)\n",
        "        a3 = sigmoid(W_3 @ a2 + b_3)\n",
        "\n",
        "        for j in range(4):\n",
        "            cost += np.power((a3[j, 0] - train_data[1][j, 0]), 2)\n",
        "\n",
        "    print(cost)\n",
        "    cost /= 100\n",
        "    total_costs.append(cost)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCHS :  0\n",
            "909.9022062294101\n",
            "EPOCHS :  1\n",
            "432.53535653830863\n",
            "EPOCHS :  2\n",
            "10.728924856794457\n",
            "EPOCHS :  3\n",
            "5.974781374636026\n",
            "EPOCHS :  4\n",
            "3.958955565568569\n",
            "EPOCHS :  5\n",
            "2.8823231269056038\n",
            "EPOCHS :  6\n",
            "2.244289774871596\n",
            "EPOCHS :  7\n",
            "1.8295328747425292\n",
            "EPOCHS :  8\n",
            "1.5398453603640996\n",
            "EPOCHS :  9\n",
            "1.3265250372097082\n",
            "EPOCHS :  10\n",
            "1.163174351129536\n",
            "EPOCHS :  11\n",
            "1.034308099303847\n",
            "EPOCHS :  12\n",
            "0.9302329124549542\n",
            "EPOCHS :  13\n",
            "0.8445594205043385\n",
            "EPOCHS :  14\n",
            "0.7729004723783345\n",
            "EPOCHS :  15\n",
            "0.7121436520891223\n",
            "EPOCHS :  16\n",
            "0.6600212770210372\n",
            "EPOCHS :  17\n",
            "0.614844038533686\n",
            "EPOCHS :  18\n",
            "0.5753294716153631\n",
            "EPOCHS :  19\n",
            "0.5404878685354936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "3yxUmeC7tq6W",
        "outputId": "db749572-3da3-42b2-df7d-2e94b678fd07"
      },
      "source": [
        "epoch_size = [x for x in range(epochs)]\n",
        "plt.plot(epoch_size, total_costs)\n",
        "plt.savefig('20_epoch_Vectorization.png')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIwRNpwWt43x",
        "outputId": "914eda38-e5c3-48c5-b108-454569a2399f"
      },
      "source": [
        "corrects = 0\n",
        "\n",
        "\n",
        "for i, x in enumerate(Xt):\n",
        "    A1 = sigmoid(W_1 @ x + b_1)\n",
        "    A2 = sigmoid(W_2 @ A1 + b_2)\n",
        "    out = sigmoid(W_3 @ A2 + b_3)\n",
        "    predicted_number = list(out).index(max(out))\n",
        "    real_number = list(Yt[i]).index(1)\n",
        "\n",
        "    if predicted_number == real_number:\n",
        "        corrects += 1\n",
        "accuracy = corrects / len(Xt)\n",
        "print(\"TEST Accuracy = \", accuracy)\n",
        "corrects = 0\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST Accuracy =  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW9TO90ft8dI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}